{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic help resource: https://github.com/WillKoehrsen/recurrent-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracted data from source & preparing dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import *\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2729\n"
     ]
    }
   ],
   "source": [
    "datasetURL = \"https://api.patentsview.org/patents/query?q={%22_and%22:[{%22_text_all%22:{%22patent_title%22:%22music%22}}]}&f=[%22patent_title%22,%22patent_abstract%22]&o={%22per_page%22:3000}\"\n",
    "connection = urlopen(datasetURL)\n",
    "response = json.load(connection)\n",
    "print(response[\"total_patent_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_title</th>\n",
       "      <th>patent_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>System for electronically generating music</td>\n",
       "      <td>A musical instrument for electronically produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Systems and methods for target training includ...</td>\n",
       "      <td>Systems and methods for target training includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Method for obtaining music data, earphone and ...</td>\n",
       "      <td>The present disclosure relates to a method for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smart gallery and automatic music video creati...</td>\n",
       "      <td>Various embodiments provide a so-called smart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apparatus and method for providing streaming m...</td>\n",
       "      <td>An apparatus and a method for sharing contents...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        patent_title  \\\n",
       "0         System for electronically generating music   \n",
       "1  Systems and methods for target training includ...   \n",
       "2  Method for obtaining music data, earphone and ...   \n",
       "3  Smart gallery and automatic music video creati...   \n",
       "4  Apparatus and method for providing streaming m...   \n",
       "\n",
       "                                     patent_abstract  \n",
       "0  A musical instrument for electronically produc...  \n",
       "1  Systems and methods for target training includ...  \n",
       "2  The present disclosure relates to a method for...  \n",
       "3  Various embodiments provide a so-called smart ...  \n",
       "4  An apparatus and a method for sharing contents...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(json.dumps(response[\"patents\"]))\n",
    "df = df.dropna()\n",
    "df.to_csv(\"./dataset/patents_music.csv\",index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2602, 2)\n",
      "(2454, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./dataset/patents_music.csv\")\n",
    "print(df.shape)\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tools and techniques are provided for identifying, collecting, and processing music-related content within a radio broadcast environment. In one embodiment, a method is provided for processing music-related broadcast radio data. The method includes receiving a plurality of broadcast radio station si'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = df['patent_abstract'].tolist()\n",
    "abstracts[100][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1847, 4, 706, 17, 48, 9, 300, 1701, 4, 102, 6, 191, 49, 118, 2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?\\\\[]{}\\t\\n|@_^~`', lower=True, split=' ')\n",
    "tokenizer.fit_on_texts(abstracts)\n",
    "sequences = tokenizer.texts_to_sequences(abstracts)\n",
    "sequences[100][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tools and techniques are provided for identifying collecting and processing music related content within a radio broadcast environment in one embodiment a method is provided for processing music related broadcast'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_words = tokenizer.index_word\n",
    "' '.join(idx_words[w] for w in sequences[100][:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(185839, 50)\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "labels = []\n",
    "\n",
    "training_length = 50\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(training_length, len(seq)):\n",
    "        \n",
    "        extract = seq[i - training_length:i + 1]\n",
    "        features.append(extract[:-1])\n",
    "        labels.append(extract[-1])\n",
    "        \n",
    "features = np.array(features)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8878\n",
      "(185839, 8878)\n"
     ]
    }
   ],
   "source": [
    "num_words = len(idx_words)+1\n",
    "print(num_words)\n",
    "label_array = np.zeros((len(features),num_words),dtype = np.int8)\n",
    "for example_index, word_index in enumerate(labels):\n",
    "    label_array[example_index][word_index]=1\n",
    "print(label_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building & training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=num_words,\n",
    "              input_length = training_length,\n",
    "              output_dim=100,\n",
    "              weights=[embedding_matrix],\n",
    "              trainable=False,\n",
    "              mask_zero=True))\n",
    "\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(64, return_sequences=False, dropout=0.1, recurrent_dropout=0.1))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_words, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint('../models/model.h5'), save_best_only=True, \n",
    "                             save_weights_only=False)]\n",
    "\n",
    "history = model.fit(X_train,  y_train, \n",
    "                    batch_size=2048, epochs=150,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
